{
  "project_metadata": {
    "project_name": "Raspberry Pi + ESP32 Air Quality ML Monitoring System",
    "location": "Kawah Putih Volcanic Crater, Ciwidey, Indonesia",
    "purpose": "Distributed air quality monitoring with 3 ESP32 sensor nodes sending data to central Raspberry Pi for ML inference",
    "architecture": "ESP32 nodes collect sensor data → Wireless transmission → Raspberry Pi performs ML inference",
    "last_updated": "2024-11-25",
    "student_background": {
      "ml_experience": "Beginner - learning ML fundamentals, exploring different algorithms",
      "embedded_experience": "Intermediate - Arduino IDE background, learning ESP-IDF",
      "programming_languages": ["Python", "C", "Arduino"],
      "preferred_framework": "PyTorch + exploring Random Forest"
    },
    "deployment_timeline": "Field deployment planned for next week (early December 2025)"
  },

  "ml_model_details": {
    "current_model": {
      "algorithm": "Supervised Learning - Multi-class Classification",
      "model_type": "Feedforward Artificial Neural Network (ANN)",
      "framework": "PyTorch",
      "deployment_platform": "Raspberry Pi (central inference node)",
      "sensor_nodes": "3 ESP32 devices (sensor reading and wireless transmission only)",
      "architecture": {
        "input_layer": 5,
        "hidden_layer_1": {"neurons": 64, "activation": "ReLU", "dropout": 0.2},
        "hidden_layer_2": {"neurons": 32, "activation": "ReLU", "dropout": 0.2},
        "output_layer": 5,
        "total_parameters": 2629
      },
      "input_features": [
        {"name": "node", "type": "categorical", "description": "Sensor node ID (1, 2, or 3) for spatial learning"},
        {"name": "so2_ugm3", "unit": "µg/m³", "description": "Sulfur Dioxide concentration"},
        {"name": "h2s_ugm3", "unit": "µg/m³", "description": "Hydrogen Sulfide concentration"},
        {"name": "temp_c", "unit": "°C", "description": "Ambient temperature"},
        {"name": "rh_pct", "unit": "%", "description": "Relative humidity"},
        {"name": "wind_speed_ms", "unit": "m/s", "description": "Wind speed"}
      ],
      "optional_features": [
        {"name": "wind_dir_deg", "unit": "degrees", "description": "Wind direction (0=N, 90=E, 180=S, 270=W)"},
        {"name": "battery_v", "unit": "volts", "description": "Node battery voltage"},
        {"name": "rssi", "unit": "dBm", "description": "WiFi signal strength"}
      ],
      "output_classes": [
        {"id": 0, "name": "Normal", "description": "Safe air quality"},
        {"id": 1, "name": "Caution", "description": "Slight concern"},
        {"id": 2, "name": "Warning", "description": "Moderate risk"},
        {"id": 3, "name": "Danger", "description": "High risk"},
        {"id": 4, "name": "Critical", "description": "Extreme danger"}
      ],
      "training_config": {
        "loss_function": "CrossEntropyLoss with safety-focused class weights",
        "optimizer": "Adam",
        "learning_rate": 0.001,
        "epochs": 50,
        "batch_size": 32,
        "train_test_split": "80/20",
        "class_weights": [1.0, 1.0, 1.2, 1.5, 2.0],
        "class_weight_reasoning": "Heavily penalize underestimating danger - prefer false alarms over missing critical conditions",
        "oversampling": "WeightedRandomSampler to balance minority classes"
      },
      "performance_v1": {
        "dataset": "Synthetic v1 (basic correlations)",
        "training_accuracy": 0.73,
        "test_accuracy": 0.70,
        "overfitting_gap": 0.03,
        "critical_class_recall": 0.92,
        "model_behavior": "Conservative - prefers overestimating danger for safety"
      },
      "performance_v2": {
        "dataset": "Synthetic v2 (realistic patterns) - IN PROGRESS",
        "status": "To be evaluated after retraining",
        "expected_improvement": "75-85% accuracy with better temporal/spatial patterns"
      }
    },
    "future_algorithms_to_explore": [
      {
        "name": "Random Forest",
        "priority": "High - student requested to understand multiple ML algorithms",
        "reason": "Compare tree-based vs neural network approach",
        "expected_outcome": "Similar or slightly better accuracy, better interpretability"
      },
      {
        "name": "XGBoost/LightGBM",
        "priority": "Medium",
        "reason": "State-of-art gradient boosting for tabular data"
      }
    ]
  },

  "data_details": {
    "synthetic_v1": {
      "dataset_type": "Synthetic (volcanic source profile)",
      "total_samples": 5000,
      "train_samples": 4000,
      "test_samples": 1000,
      "generation_method": "Rule-based with basic environmental correlations",
      "limitations": [
        "No temporal continuity (random jumps between readings)",
        "Simplistic wind effects (speed only, no direction)",
        "No spatial variation between nodes",
        "Overly smooth patterns without realistic spikes"
      ],
      "result": "70% test accuracy - adequate but room for improvement"
    },
    "synthetic_v2": {
      "dataset_type": "Improved synthetic with realistic volcanic patterns",
      "total_samples": 60000,
      "samples_per_node": 20000,
      "nodes": 3,
      "generation_method": "Advanced temporal and spatial modeling",
      "improvements": [
        "Temporal continuity: Smooth transitions with occasional spikes (5% probability)",
        "Spatial variation: Node-specific base pollution levels based on distance from fumarole",
        "Mountain valley wind cycles: Daytime upslope (6am-6pm), nighttime downslope (6pm-6am)",
        "Wind dispersion modeling: Direction and speed affect pollutant concentration per node",
        "Environmental correlations: Temperature/humidity daily cycles, battery drain",
        "Realistic ranges: SO₂ (60-1080 µg/m³), H₂S (0-360 µg/m³)"
      ],
      "node_layout": {
        "node_1": "Near fumarole (volcanic source) - highest pollution baseline",
        "node_2": "Middle distance - moderate pollution baseline",
        "node_3": "Tourist area (farthest) - lowest pollution baseline, risk of plume drift"
      },
      "files": [
        "kawah_putih_synthetic_v2.csv (unlabeled raw data)",
        "kawah_putih_labeled_v2.csv (to be generated after labeling)"
      ],
      "status": "Generated, ready for labeling"
    },
    "labeling_strategy": {
      "method": "Rule-based using official Kawah Putih safety thresholds",
      "source": "Volcanic monitoring guidelines for Kawah Putih",
      "thresholds_so2_10min_avg": {
        "normal": "< 100 µg/m³",
        "caution": "100-200 µg/m³",
        "warning": "200-500 µg/m³",
        "danger": "≥ 500 µg/m³"
      },
      "thresholds_h2s_10_30min_avg": {
        "normal": "< 0.005 ppm (≈7 µg/m³)",
        "caution": "0.005-0.03 ppm",
        "warning": "0.03-0.1 ppm",
        "danger": "≥ 0.1 ppm",
        "critical": "≥ 1.0 ppm (public) / ≥ 5-10 ppm (operators)"
      },
      "combination_logic": {
        "description": "Weighted average with safety override",
        "rules": [
          "Assign severity score: Normal=0, Caution=1, Warning=2, Danger=3, Critical=4",
          "Score SO₂ and H₂S separately",
          "IF either pollutant ≥ Danger (score 3+): Final = max(SO₂_score, H₂S_score)",
          "ELSE: Final = round(average(SO₂_score, H₂S_score))",
          "Convert final score back to label"
        ],
        "rationale": "Balance accuracy for lower severity while maintaining safety-first for dangerous conditions"
      },
      "conversion_formulas": {
        "h2s_ugm3_to_ppm": "PPM = (h2s_ugm3 * constant) / 34080, where constant = (273.15 + temp_c) * 0.082057",
        "so2_ugm3_to_ppm": "PPM = (so2_ugm3 * constant) / 64060 (for reference only)"
      }
    },
    "real_data_plan": {
      "status": "Deployment scheduled for next week",
      "collection_method": "3 ESP32 nodes at Kawah Putih, 10-second intervals",
      "purpose": "Replace synthetic data with real sensor readings for production model",
      "expected_accuracy_improvement": "85-90% with real labeled data"
    }
  },

  "completed_steps": {
    "step_1": {
      "name": "Understanding Fundamentals",
      "status": "✅ Completed",
      "key_learnings": [
        "ESP32 constraints vs Raspberry Pi capabilities",
        "Model size calculation and quantization",
        "Train/test split concept",
        "Computational load estimation"
      ]
    },
    "step_2": {
      "name": "Synthetic Dataset Generation v1",
      "status": "✅ Completed (superseded by v2)",
      "files_generated": ["air_quality_train.csv", "air_quality_test.csv"],
      "script": "01_synthetic_dataset_generator.py"
    },
    "step_3": {
      "name": "Model Training v1",
      "status": "✅ Completed (baseline established)",
      "files_generated": ["best_model.pth", "confusion_matrix.png", "training_curves.png"],
      "script": "02_train_model.py",
      "result": "70% test accuracy - baseline for comparison"
    },
    "step_4": {
      "name": "ONNX Conversion",
      "status": "✅ Completed (optional, not needed for Raspberry Pi)",
      "files_generated": ["air_quality_model.onnx"],
      "script": "03_onnx_conversion.py"
    },
    "step_5": {
      "name": "Weight Extraction to C Arrays",
      "status": "✅ Completed (not needed for final deployment)",
      "files_generated": ["model_weights.h"],
      "script": "04_weight_extractor.py"
    },
    "step_6": {
      "name": "C Inference Implementation",
      "status": "✅ Completed (educational exercise)",
      "files_generated": ["model_inference.h", "model_inference.c"]
    },
    "step_7": {
      "name": "Real Data Labeling Script",
      "status": "✅ Completed",
      "files_generated": ["label_real_data.py"],
      "description": "Python script to label raw sensor data using official Kawah Putih thresholds",
      "features": [
        "Temperature-dependent H₂S conversion (µg/m³ → ppm)",
        "Separate SO₂ and H₂S classification",
        "Combination logic with safety override",
        "Class distribution analysis",
        "Outputs ML-ready labeled CSV"
      ]
    },
    "step_8": {
      "name": "Improved Synthetic Dataset Generation v2",
      "status": "✅ Completed",
      "files_generated": ["kawah_putih_synthetic_v2.csv"],
      "script": "05_improved_synthetic_generator.py",
      "improvements": [
        "Temporal continuity with random walk + mean reversion",
        "Spatial variation across 3 nodes",
        "Mountain valley wind cycles (diurnal pattern)",
        "Wind dispersion modeling (speed + direction)",
        "Occasional spikes (5% probability)",
        "Environmental correlations (temp/humidity cycles)",
        "60,000 total samples (20,000 per node)"
      ]
    }
  },

  "current_step": {
    "step_number": 9,
    "name": "Label Synthetic v2 Dataset and Retrain Model",
    "status": "⏳ Ready to Execute",
    "description": "Apply labeling script to improved synthetic data, then retrain neural network to measure accuracy improvement",
    "action_items": [
      "1. Run labeling script on kawah_putih_synthetic_v2.csv",
      "2. Analyze class distribution in labeled data",
      "3. Split into train/test (80/20)",
      "4. Retrain PyTorch model with same architecture",
      "5. Compare new accuracy vs baseline 70%",
      "6. Decide if accuracy is sufficient or needs further tuning"
    ],
    "expected_outcome": "75-85% test accuracy due to more realistic patterns"
  },

  "pending_steps": [
    {
      "step_number": 10,
      "name": "Explore Random Forest Algorithm",
      "status": "Not Started - High Priority",
      "description": "Student wants to understand multiple ML algorithms and compare performance",
      "approach": [
        "Train Random Forest on same labeled dataset",
        "Compare accuracy with Neural Network",
        "Analyze feature importance (interpretability advantage of RF)",
        "Discuss trade-offs: accuracy, inference speed, model size, interpretability"
      ],
      "learning_goals": [
        "Understand tree-based vs neural network approaches",
        "Learn when to use each algorithm type",
        "Gain broader ML algorithm knowledge"
      ]
    },
    {
      "step_number": 11,
      "name": "Raspberry Pi Inference Implementation",
      "status": "Not Started",
      "description": "Implement PyTorch inference on Raspberry Pi to receive data from ESP32 nodes",
      "components": [
        "Python inference script (load best_model.pth, run predictions)",
        "Data receiver from ESP32 nodes (WiFi/MQTT/ESP-NOW)",
        "Display/logging/alert system",
        "Handle data from 3 nodes simultaneously"
      ]
    },
    {
      "step_number": 12,
      "name": "Create ESP32 Sensor Node Firmware",
      "status": "Not Started",
      "description": "Implement ESP32 firmware to read sensors and transmit data to Raspberry Pi",
      "components": [
        "Sensor reading (H₂S, SO₂, wind speed, temperature, humidity)",
        "Data packaging (JSON or binary)",
        "Wireless transmission (MQTT recommended for 3 nodes)",
        "Low power optimization",
        "Battery monitoring"
      ]
    },
    {
      "step_number": 13,
      "name": "Integrate ML Inference with Data Pipeline",
      "status": "Not Started",
      "flow": [
        "Receive sensor data from ESP32 node via MQTT",
        "Parse and validate data",
        "Run PyTorch inference",
        "Get classification and confidence score",
        "Store result with node ID and timestamp",
        "Trigger alerts for Danger/Critical conditions"
      ]
    },
    {
      "step_number": 14,
      "name": "Field Testing at Kawah Putih",
      "status": "Planned for Next Week",
      "activities": [
        "Deploy 3 ESP32 nodes at strategic locations",
        "Node 1: Near fumarole (volcanic source)",
        "Node 2: Middle distance monitoring point",
        "Node 3: Tourist area (safety monitoring)",
        "Set up Raspberry Pi as central monitoring station",
        "Test wireless connectivity and range",
        "Calibrate sensors with known reference (if available)",
        "Collect real sensor data for 24-48 hours",
        "Validate predictions against actual conditions"
      ]
    },
    {
      "step_number": 15,
      "name": "Retrain with Real Data",
      "status": "Post-Deployment",
      "description": "Replace synthetic data with real field data and retrain for production model",
      "expected_improvement": "85-90% accuracy with real patterns"
    }
  ],

  "key_technical_decisions": {
    "why_raspberry_pi_for_inference": "Centralized inference is more practical. Raspberry Pi handles ML while ESP32s focus on sensor reading and wireless transmission. Easier to update model and maintain.",
    "why_pytorch_not_onnx": "Raspberry Pi has full Python support. Using PyTorch directly is simplest - just load best_model.pth and run inference. No conversion needed.",
    "why_3_sensor_nodes": "Coverage across volcanic crater area. 3 ESP32 nodes placed strategically (near source, middle, tourist area) provide spatial awareness of gas dispersion patterns.",
    "why_improved_synthetic_data": "Original synthetic data achieved 70% accuracy but lacked realistic patterns. Version 2 adds temporal continuity, spatial variation, mountain valley winds, and wind dispersion to better prepare model for real deployment.",
    "why_balanced_labeling": "Student prioritizes accuracy over pure safety-first. Combination logic uses weighted average for Normal-Warning range, with safety override only for Danger/Critical levels.",
    "why_explore_random_forest": "Student wants to understand multiple ML algorithms beyond neural networks. Comparing ANN vs RF provides broader ML education and helps choose best approach.",
    "node_spatial_layout": "Node 1 (fumarole) captures source emissions. Node 2 (middle) monitors dispersion. Node 3 (tourist area) provides public safety monitoring and can detect plume drift events."
  },

  "important_context": {
    "student_learning_journey": [
      "Started with neural network basics and embedded ML concepts",
      "Achieved 70% baseline accuracy, initially disappointed",
      "Considered switching to Random Forest for better accuracy",
      "Realized data quality is root cause through guided questioning",
      "Chose to improve synthetic data first (Path A)",
      "Plans to explore Random Forest after (learning goal)",
      "Deployment deadline: next week - needs working prototype"
    ],
    "student_goals": {
      "primary": "Get working prototype with good accuracy before field deployment",
      "secondary": "Understand multiple ML algorithms (educational)",
      "tertiary": "Successfully deploy at Kawah Putih and collect real data"
    },
    "teaching_moments": [
      "Helped student identify data quality as bottleneck vs algorithm choice",
      "Guided through combination logic design for labeling",
      "Encouraged prediction before running code (verify understanding)",
      "Emphasized real data will ultimately provide best accuracy"
    ]
  },

  "repository_structure": {
    "current_layout": {
      "data/": [
        "air_quality_train.csv (v1 - baseline)",
        "air_quality_test.csv (v1 - baseline)",
        "kawah_putih_synthetic_v2.csv (v2 - improved, unlabeled)",
        "kawah_putih_labeled_v2.csv (v2 - to be generated)"
      ],
      "experiments/": [
        "training1_terminal_output.txt",
        "training1_confusion_matrix.png",
        "training1_curves.png"
      ],
      "models/": [
        "best_model.pth (v1 - 70% accuracy baseline)",
        "best_model_v2.pth (to be trained on improved data)",
        "air_quality_model.onnx (optional)"
      ],
      "src/": [
        "01_synthetic_dataset_generator.py (v1 - baseline)",
        "02_train_model.py",
        "03_onnx_conversion.py (optional)",
        "04_weight_extractor.py (not needed)",
        "05_improved_synthetic_generator.py (v2)",
        "06_label_real_data.py",
        "07_train_random_forest.py (to be created)"
      ],
      "raspberry_pi/": [
        "inference.py (to be created)",
        "data_receiver.py (to be created)",
        "main.py (to be created)"
      ],
      "esp32_nodes/": [
        "sensor_node firmware (to be created)"
      ],
      "README.md": "Project documentation",
      "project_state.json": "This file - project tracking"
    }
  },

  "next_session_priorities": [
    {
      "priority": 1,
      "task": "Label synthetic v2 dataset and retrain model",
      "why": "Measure if improved data quality actually increases accuracy",
      "estimated_time": "30-45 minutes"
    },
    {
      "priority": 2,
      "task": "Implement and compare Random Forest",
      "why": "Student's learning goal - understand multiple algorithms",
      "estimated_time": "45-60 minutes"
    },
    {
      "priority": 3,
      "task": "Begin Raspberry Pi inference implementation",
      "why": "Critical for next week's field deployment",
      "estimated_time": "1-2 hours"
    }
  ],

  "questions_for_next_session": [
    "What accuracy did the model achieve on synthetic v2 data?",
    "How does Random Forest compare to Neural Network?",
    "Do you have Raspberry Pi hardware ready?",
    "Do you have the actual sensors (H₂S, SO₂, wind, temp, humidity)?",
    "What wireless communication protocol do you want to use? (MQTT recommended)"
  ],

  "known_issues": {
    "quantization_failure": {
      "description": "ONNX to Int8 quantization fails with shape inference error",
      "status": "Not critical - using Float32 on Raspberry Pi",
      "workaround": "Raspberry Pi has plenty of resources for Float32 model"
    }
  },

  "future_enhancements": [
    "Retrain with real Kawah Putih sensor data (post-deployment)",
    "Add time-series analysis for trend prediction (LSTM/GRU)",
    "Implement OTA updates for model weights",
    "Add more sensor inputs (atmospheric pressure, wind direction as primary feature)",
    "Explore ensemble methods (combine ANN + RF predictions)",
    "Add web dashboard for real-time monitoring of all 3 nodes",
    "Implement automated alerts via Telegram/SMS for Danger/Critical conditions",
    "Battery optimization strategies for ESP32 nodes",
    "Solar power integration for long-term deployment"
  ],

  "reference_links": {
    "who_air_quality_guidelines": "Used for general pollutant thresholds",
    "kawah_putih_safety_thresholds": "Official guidelines used for labeling logic",
    "kawah_putih_research": "Scientific data on volcanic gas concentrations",
    "esp_idf_docs": "https://docs.espressif.com/projects/esp-idf/",
    "pytorch_docs": "https://pytorch.org/docs/",
    "sklearn_random_forest": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
  }
}